---
keyword: [Flink全托管, 开发, Python]
---

# 作业开发

本文为您介绍**Flink全托管**Python作业开发的限制说明、开发方法、Connector使用等。

## 限制说明

    由于**Flink全托管**产品受部署环境、网络环境等因素的影响，所以开发**Flink全托管**Python作业，需要注意以下限制：

    -   仅支持开源Flink V1.12版本。
    -   **Flink全托管**集群已预装了Python版本为Python 3.7.9，且Python环境中已经预装了Pandas、NumPy、PyArrow等常用的Python库。因此需要您在Python 3.7版本编辑代码。
    -   **Flink全托管**运行环境使用的是JDK1.8，如果Python作业中依赖第三方JAR包，请确保JAR包兼容JDK1.8。
    -   仅支持开源Scala V2.11版本，如果Python作业中依赖第三方JAR包，请确保使用Scala V2.11对应的JAR包依赖。

    **Flink全托管**集群已安装下列软件包。
    |Flink版本|软件包|版本|
    |--|---|--|
    |**Flink 1.12**|apache-beam|2.23.0|
    |avro-python3|1.9.1|
    |certifi|2020.12.5|
    |chardet|4.0.0|
    |cloudpickle|1.2.2|
    |crcmod|1.7|
    |cython|0.29.16|
    |dill|0.3.1.1|
    |docopt|0.6.2|
    |fastavro|0.23.6|
    |future|0.18.2|
    |grpcio|1.29.0|
    |hdfs|2.6.0|
    |httplib2|0.17.4|
    |idna|2.10|
    |jsonpickle|1.2|
    |mock|2.0.0|
    |numpy|1.19.5|
    |oauth2client|3.0.0|
    |pandas|0.25.3|
    |pbr|5.5.1|
    |pip|20.1.1|
    |protobuf|3.15.3|
    |py4j|0.10.8.1|
    |pyarrow|0.17.1|
    |pyasn1-modules|0.2.8|
    |pyasn1|0.4.8|
    |pydot|1.4.2|
    |pymongo|3.11.3|
    |pyparsing|2.4.7|
    |python-dateutil|2.8.0|
    |pytz|2021.1|
    |requests|2.25.1|
    |rsa|4.7.2|
    |setuptools|47.1.0|
    |six|1.15.0|
    |typing-extensions|3.7.4.3|
    |urllib3|1.26.3|
    |wheel|0.36.2|

## 作业开发

    您需要在线下完成Python API作业开发后，再在**Flink全托管**控制台上提交作业到集群上运行。您可以参见以下文档开发**Flink全托管**产品业务代码：

    -   Apache Flink V1.12业务代码开发，请参见[Flink Python API开发指南](https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/python/)。
    -   Apache Flink编码过程中遇到的问题及解决方法，请参见[常见问题](https://flink.apache.org/gettinghelp.html)。

## Connector使用

    **Flink全托管**产品提供了多种上下游存储（Connector）的支持，所支持的上下游存储（Connector）列表，请参见[支持的上下游存储](/cn.zh-CN/Flink全托管/产品概览/支持的上下游存储.md)。如果Python作业中需要使用**Flink全托管**产品所提供的connector，可以参考[Connector使用](/cn.zh-CN/Flink全托管/Flink Datastream开发指南/作业开发.md#Connector使用)，了解更多关于connector的信息，并下载合适版本的connector，在Python作业中使用。

    不管是**Flink全托管**产品所提供的connector，还是您自己开发的connector，如果需要在Python作业中使用，可以参考如下步骤：

    - 在左侧导航栏，单击**资源上传**，上传需要使用的connector的JAR包。
    - 在作业的**基础配置**页面，**附加依赖文件**项，选择需要使用的connector的JAR包。
    - 在作业的**高级配置**页面，**更多 Flink 配置**项，添加如下配置：

      ```
      # 假如需要依赖多个connector JAR包，且名字分别为connector-1.jar和connector-2.jar
      pipeline.classpaths: 'file:///flink/usrlib/connector-1.jar;file:///flink/usrlib/connector-2.jar'
      ```
